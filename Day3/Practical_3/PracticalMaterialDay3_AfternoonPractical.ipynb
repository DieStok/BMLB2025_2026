{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "181fa6c2",
   "metadata": {},
   "source": [
    "## Afternoon practical day 3\n",
    "\n",
    "You've just learned about convolutional neural networks. There will be a sneak peek into them at the end. For now, however, we finally implement backpropagation.\n",
    "\n",
    "**Notes**:\n",
    "\n",
    "1. there's a lot of math in this notebook. This is to help you, not to make your life hell. So know this: the goal here is to implement backpropagation with linear algebra. As long as you understand what backpropagation aims to do and how that is embedded in the formulae, that's mission accomplished. Try to implement it, but if you don't manage there is always the answers. Skip whatever math you don't want to read, especially the recaps!\n",
    "2. There is time to finish this tomorrow: the more involved practical on multiple sequence alignment and clustering has been removed from the course, so tomorrow has only 2 short practicals planned, both on clustering methods that are easily understood and well-known. (K-means and basic hierarchical clustering). Hence: go at your own pace, get as far as you can.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056cc836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to set things up\n",
    "import ipywidgets as widgets, numpy as np, pandas as pd\n",
    "from numpy.random import default_rng\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Markdown, Math\n",
    "import scipy\n",
    "from scipy.optimize import fmin_bfgs, fmin_cg, fmin, fmin_l_bfgs_b, fmin_tnc\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07d8ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# important functions\n",
    "def mySigmoid(data):\n",
    "    data = np.array(data)\n",
    "    output = 1 / (1 + np.exp(-data))\n",
    "    return output\n",
    "\n",
    "\n",
    "def mySigmoidGradient(x):\n",
    "    outcome = mySigmoid(x) * (1 - mySigmoid(x))\n",
    "    return outcome\n",
    "\n",
    "\n",
    "def nnCostFunction(\n",
    "    nnThetas,\n",
    "    X,\n",
    "    y,\n",
    "    lambda_=0,\n",
    "    inputLayerSize=784,\n",
    "    hiddenLayerSize=25,\n",
    "    classLabels=10,\n",
    "    smallValueToRemoveInfinity=1e-12,\n",
    "):\n",
    "    m = len(X)\n",
    "    # reshaping the list of parameters to matrices\n",
    "    hiddenLayerParamNr = hiddenLayerSize * (inputLayerSize + 1)\n",
    "    thetaOneMatrix = np.reshape(\n",
    "        nnThetas[0:hiddenLayerParamNr], newshape=(hiddenLayerSize, inputLayerSize + 1)\n",
    "    )\n",
    "    outputLayerParamStart = hiddenLayerParamNr\n",
    "    thetaTwoMatrix = np.reshape(\n",
    "        nnThetas[outputLayerParamStart:], newshape=(classLabels, hiddenLayerSize + 1)\n",
    "    )\n",
    "\n",
    "    # calculating the forward pass\n",
    "    inputs = np.c_[np.ones(shape=(len(X), 1)), X]\n",
    "    weightedSumHL = inputs @ thetaOneMatrix.T\n",
    "    activationsHL = mySigmoid(weightedSumHL)\n",
    "\n",
    "    inputsOL = np.c_[np.ones(shape=(len(activationsHL), 1)), activationsHL]\n",
    "    weightedSumOL = inputsOL @ thetaTwoMatrix.T\n",
    "    activationsOL = mySigmoid(weightedSumOL)\n",
    "\n",
    "    # cost\n",
    "    J = (\n",
    "        1\n",
    "        / m\n",
    "        * np.sum(\n",
    "            (\n",
    "                -(y * np.log(activationsOL + smallValueToRemoveInfinity))\n",
    "                - ((1 - y) * np.log(1 - activationsOL + smallValueToRemoveInfinity))\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # regularised cost\n",
    "    # remember: units in the rows, their parameters in the columns\n",
    "    # Hence, [:,1:] removes the columns with the bias term.\n",
    "    regThetaOne = np.sum(np.square(thetaOneMatrix[:, 1:]))\n",
    "    regThetaTwo = np.sum(np.square(thetaTwoMatrix[:, 1:]))\n",
    "    regCost = J + (lambda_ / (2 * m)) * (regThetaOne + regThetaTwo)\n",
    "\n",
    "    return regCost\n",
    "\n",
    "\n",
    "def numericalGradientApproximation(nnThetas, X, y, lambda_=0, e=1e-4, indexToStop=200):\n",
    "    nnThetasMinusE = nnThetas - e\n",
    "    nnThetasPlusE = nnThetas + e\n",
    "    listGradients = []\n",
    "    for index, value in enumerate(nnThetas):\n",
    "        if index % 50 == 0:\n",
    "            print(\"Parameter \" + str(index) + \" out of \" + str(len(nnThetas)))\n",
    "        minusEThetas = nnThetas.copy()\n",
    "        minusEThetas[index] = nnThetasMinusE[index]\n",
    "        minusECost = nnCostFunction(minusEThetas, X, y, lambda_)\n",
    "        plusEThetas = nnThetas.copy()\n",
    "        plusEThetas[index] = nnThetasPlusE[index]\n",
    "        plusECost = nnCostFunction(plusEThetas, X, y, lambda_)\n",
    "        numericalGradApproxThisTheta = (plusECost - minusECost) / (2 * e)\n",
    "        # Only do this for the first ~150 thetas. Otherwise it takes entirely too long!\n",
    "        listGradients.append(numericalGradApproxThisTheta)\n",
    "        if index == indexToStop:\n",
    "            break\n",
    "    return np.array(listGradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4728783",
   "metadata": {},
   "source": [
    "## Backpropagation recap\n",
    "### Feel free to skip if you've heard enough about it already (specifically, skip to \"Backpropagation-linear-algebra\")\n",
    "\n",
    "Let's take a moment to step back and understand what you want to do here. We want to change the parameters of the network such that we can decrease the cost on our training examples. This involves calculating partial derivatives of the cost with respect to all the parameters in the network. The _way_ we do that is by chaining many partial derivatives together: the chain rule of derivation will be getting some heavy use. To recap what you've learned so far: the fundamental equations of backpropagation are:\n",
    "1. **The error of a neuron**:\n",
    "$$\\delta^{(l)}_j = \\frac{\\partial C}{\\partial z^{(l)}_j} = \\frac{\\partial C}{\\partial a^{(l)}_j} \\cdot \\frac{\\partial a^{(l)}_j}{\\partial z^{(l)}_j}$$\n",
    "This says: the error of a certain neuron _j_ in layer _l_ is equal to the partial derivative of the cost with respect to the weighted sum it produces (remember, $z^{(l)}_j$ is just $\\sum \\limits _{i=1} ^{n_{weights}} w_i \\cdot a^{(l-1)}_i  + b$. In other words: in our case a neuron in the output network takes in 25 inputs ($a^{(l-1)}_1$ until $a^{(l-1)}_{25}$) and multiplies them with a separate weight for each, takes the sum, and adds the bias). And that $\\frac{\\partial C}{\\partial z^{(l)}_j}$ in turn is equal to the partial derivative of the cost with respect to the activation, times the partial derivative of the activation with respect to this weighted sum. This is because of the chain rule: <br>![ChainRule](ChainRule.PNG) <br> We want the derivative of the cost relative to the weighted sum (because we can change those weights and the bias), but those are passed through the nonlinear sigmoid activation function. So in our case, $ f = \\sigma(g)$ and $g(inputs, weights, biases) = \\sum \\limits _{i=1} ^{n_{weights}} w_{i,j} \\cdot a^{(l-1)}_i  + b^{(l)}_j = z^{(l)}_j$. Luckily the derivative of the sigmoid function is easy: $\\sigma(x) \\cdot \\sigma(1-x)$. Note also that our function g depends on the inputs of the previous layer, the weights, and the bias, so we need partial derivatives with respect to each of these! <br> <br> If we fill that all in we get:\n",
    "$$\n",
    " \\delta^{(l)}_j = \\frac{\\partial C}{\\partial a^{(l)}_j} \\cdot \\frac{\\partial a^{(l)}_j}{\\partial z^{(l)}_j} = \\frac{\\partial C}{\\partial {sigmoid(\\sum \\limits _{i=1} ^{n_{weights}} w_{i,j} \\cdot a^{(l-1)}_i  + b^{(l)}_j})} \\cdot \\frac{{\\partial {sigmoid(\\sum \\limits _{i=1} ^{n_{weights}} w_{i,j} \\cdot a^{(l-1)}_i  + b^{(l)}_j})}}{{\\partial \\sum \\limits _{i=1} ^{n_{weights}} w_{i,j} \\cdot a^{(l-1)}_i  + b^{(l)}_j}}\n",
    "$$ \n",
    "Which equals:\n",
    "$$ \\delta^{(l)}_j = \\frac{\\partial C}{\\partial a^{(l)}_j} \\cdot \\frac{\\partial a^{(l)}_j}{\\partial z^{(l)}_j} = \\frac{\\partial C}{\\partial {sigmoid(\\sum \\limits _{i=1} ^{n_{weights}} w_{i,j} \\cdot a^{(l-1)}_i  + b^{(l)}_j})} \\cdot {sigmoid(z^{(l)}_j) \\cdot (1 - sigmoid(z^{(l)}_j))}$$\n",
    "You can just think of delta as the partial derivative of the cost w.r.t. the weighted sum that a certain neuron produces. To be entirely sure that this is understood, look at the image below: ![image](ExampleNeuralNetwork5.PNG) The cost function in this case hinges on $$\\begin{bmatrix}a^{(l)}_1 = 0.33 \\\\ a^{(l)}_2 = 0.8 \\\\ a^{(l)}_3 = 0.189\\end{bmatrix}$$ So we have here $$\\begin{bmatrix}\\delta^{(l)}_1 = \\sigma'(0 -  0.330) = \\sigma'(-0.33) \\\\ \\delta^{(l)}_2 = \\sigma'(1 - 0.800) = \\sigma'(0.2) \\\\ \\delta^{(l)}_3 = \\sigma'(0 - 0.189) = \\sigma'(-0.189)\\end{bmatrix}$$ We can calculate those values, and they turn out to be  $$\\begin{bmatrix}\\delta^{(l)}_1 \\approx 0.24 \\\\ \\delta^{(l)}_2 \\approx 0.25 \\\\ \\delta^{(l)}_3 \\approx 0.25\\end{bmatrix}$$ If those values seem awfully similar to you, remember that between -1 and 1 the sigmoid curve pretty much [looks like a straight line](https://keisan.casio.com/exec/system/15157249643325#!) and hence it makes sense that its gradient there is pretty much one value. <br> **Now it turns out that for the derivative of cross entropy (the cost function we're using instead of MSE), $\\frac{\\partial C}{\\partial z^{(l)}_j}$ just simplifies to $\\delta^{(l)}_j$ because it cancels out the sigmoid derivative. See the derivative of cross entropy [here](https://stats.stackexchange.com/a/371282) and look at the Deep Learning Crash Course slides in the extra material if you want to learn more!**\n",
    "Okay, so we now have a partial derivative for the cost w.r.t. the neurons in the output layer. With that we can move on to part 2 and 3. <br> <br>\n",
    "\n",
    "2. **The partial derivative of the cost w.r.t. a bias**. This is just:  $$\\frac{\\partial C}{\\partial b^{(l)}_j} = \\frac{\\partial C}{\\partial a^{(l)}_j} \\cdot \\frac{\\partial a^{(l)}_j}{\\partial z^{(l)}_j} \\cdot \\frac{\\partial z^{(l)}_j}{\\partial b^{(l)}_j} = \\delta^{(l)}_j \\cdot \\frac{\\partial z^{(l)}_j}{\\partial b^{(l)}_j}$$ Or in words: how the cost is affected by a certain bias is how the cost is changed by a certain activation times how that activation is changed by a weighted sum times how that weighted sum is changed by a change in its bias. It is easy to see that $$\\frac{\\partial z^{(l)}_j}{\\partial b^{(l)}_j} = \\frac{\\partial \\sum \\limits _{i=1} ^{n_{weights}} w_i \\cdot a^{(l-1)}_i  + b^{(l)}_j}{\\partial {b^{(l)}_j}} = 1 $$This is just like $$\\frac{\\partial (ax + b)}{\\partial {b}} = 1 $$ while $$\\frac{\\partial (ax + b)}{\\partial {a}} = x $$Taken together, the partial derivative of the cost relative to a certain bias is just $$\\delta^{(l)}_j$$\n",
    "\n",
    "3. **The partial derivative of the cost w.r.t. a weight**. This is just: $$\\frac{\\partial C}{\\partial w^{(l)}_{i,j}} = \\frac{\\partial C}{\\partial a^{(l)}_j} \\cdot \\frac{\\partial a^{(l)}_j}{\\partial z^{(l)}_j} \\cdot \\frac{\\partial z^{(l)}_j}{\\partial w^{(l)}_{i,j}} = \\delta^{(l)}_j \\cdot \\frac{\\partial z^{(l)}_j}{\\partial w^{(l)}_{i,j}}$$ For our toy network above, i runs from 1 to 2: there are 2 inputs for each neuron in the output layer, 1 for each hidden unit, and they both have a weight. j runs from 1 to 3 for the 3 neurons in the output layer. If we expand the term on the right and calculate it, we get: $$\\frac{\\partial z^{(l)}_j}{\\partial w^{(l)}_{i,j}} = \\frac{\\partial \\sum \\limits _{i=1} ^{n_{weights}} w_{i,j} \\cdot a^{(l-1)}_i  + b^{(l)}_j}{\\partial {w^{(l)}_{i,j}}} =  a^{(l-1)}_i$$ Putting it together, we get: $$\\delta^{(l)}_j \\cdot a^{(l-1)}_i$$ <br> <br>\n",
    "\n",
    "4. **Computing the partial derivative of the cost w.r.t. the activations from the previous layer --> propagating the errors back one layer**. We've done the partial derivatives of the weights and the biases, but we also want to calculate the partial derivative of the cost function relative to the input activations the output layer got. Here goes: \n",
    "$$\\frac{\\partial C}{\\partial z^{(l-1)}_{j}} = \\frac{\\partial C}{\\partial a^{(l)}_j} \\cdot \\frac{\\partial a^{(l)}_j}{\\partial z^{(l)}_j} \\cdot \\frac{\\partial z^{(l)}_j}{\\partial a^{(l-1)}_{j}} \\cdot \\frac{\\partial a^{(l-1)}_j}{\\partial z^{(l-1)}_{j}} = \\delta^{(l)}_j \\cdot \\frac{\\partial z^{(l)}_j}{\\partial a^{(l-1)}_{j}} \\cdot \\sigma'(z^{(l-1)}_j)$$\n",
    "In words: How the partial derivative of the cost hinges on the weighted sum $z^{(l-1)}_{j}$ in the previous layer is how the cost hinges on the activations in the output layer, times how the activations in the output layer hinge on the weighted sum that the output layer calculates, times how that weighted sum hinges on the activations it takes in from layer l-1, times how those activations hinge on their weighted sum. We already know $$\\frac{\\partial C}{\\partial a^{(l)}_j} \\cdot \\frac{\\partial a^{(l)}_j}{\\partial z^{(l)}_j} = \\delta^{(l)}_j \\\\ \\text{and} \\frac{\\partial a^{(l-1)}_j}{\\partial z^{(l-1)}_{j}} \\text{is just the sigmoid derivative: } \\sigma(z^{(l-1)}_j) \\cdot (1-\\sigma(z^{(l-1)}_j))$$ So all we need to do is calculate: $$\\frac{\\partial z^{(l)}_j}{\\partial a^{(l-1)}_{j}}$$ which is just:\n",
    "$$\\frac{\\partial z^{(l)}_j}{\\partial a^{(l-1)}_{j}} = \\frac{\\partial \\sum \\limits _{j=1} ^{n_{weights}} w_{j} \\cdot a^{(l-1)}_j  + b^{(l)}_j}{\\partial {a^{(l-1)}_{j}}} =  \\sum \\limits _{j=1} ^{n_{weights}} w_{j}$$. Finally this results in: $$\\delta^{(l-1)}_j = \\sum \\limits _{j=1} ^{n_{weights}} w_{j} \\cdot \\delta^{(l)}_j \\cdot \\sigma'(z^{(l-1)}_j)$$\n",
    "\n",
    "## Phew, that's a lot. The executive summary:\n",
    "1. Calculate error in the final layer with $\\delta_j^{(L)} = \\frac{\\partial C}{\\partial a^{(L)}_j} \\cdot \\frac{\\partial a^{(L)}_j}{\\partial z^{(l)}_j} = \\frac{\\partial C}{\\partial a^{(L)}_j} \\cdot \\sigma'(z^{(L)}_j)$. **For the cross entropy cost function that we use, this is just $a^{(L)}_j - y_j$**\n",
    "2. The partial derivative w.r.t. to each bias is just $\\delta_j^{(l)}$.\n",
    "3. The partial derivative of the cost w.r.t. each weight is just $\\delta_j^{(l)} \\cdot a^{(l-1)}_j$\n",
    "4. You can propagate the initial error back by multiplying it with the weights and multiplying with the derivative of the sigmoid function to get $\\delta^{(l-1)}_j = \\sum \\limits _{j=1} ^{n_{weights}} w_{j} \\cdot \\delta^{(l)}_j \\sigma'(z^{(l-1)}_j)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9b43e0",
   "metadata": {},
   "source": [
    "## Implementing this with linear algebra\n",
    "\n",
    "Now the above has myriad indices (i,j,l) to show what weight of what neuron in what layer we are talking about, because we need to do these things for every weight in every neuron in every layer, and that for every training example as well. You can do this using loops for a single training example, but that is not the [~~wae~~](https://knowyourmeme.com/memes/ugandan-knuckles) way.\n",
    "\n",
    "Instead, we'll do this using linear algebra. Here's a toy network again: ![image](ToyNetworkLinAlg2.PNG) \n",
    "What's changed is that I have already calculated an (average) $\\delta^{(L)}_j$ based on two training examples. These training examples have 2 features each. First a recap of the forward pass\n",
    "\n",
    "## Forward pass linear algebra recap (feel free to skip)\n",
    "\n",
    "To make matters simple, here is a small example network where everything is annotated. Let's walk through what the linear algebra implementation of forward propagation would look like. <br>\n",
    "\n",
    "![image](../../Day3/Practical_3/ExampleNeuralNetwork5.PNG) <br>\n",
    "\n",
    "The data looks like:\n",
    "\n",
    "$$\\begin{bmatrix} 1 & feat_1val_1 & feat_2val_1 \\\\ 1 & feat_1val_2 & feat_2val_2 \\end{bmatrix}$$\n",
    "\n",
    "The first matrix with the weights and biases is $\\Theta^{(1)}$ and looks like this:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "\\text{bias}_{\\text{neuron}_1} & \\text{weight}_{\\text{input}_1,\\text{neuron}_1} & \\text{weight}_{\\text{input}_2,\\text{neuron}_1} \\\\  \n",
    "\\text{bias}_{\\text{neuron}_2} & \\text{weight}_{\\text{input}_1,\\text{neuron}_2} & \\text{weight}_{\\text{input}_2,\\text{neuron}_2} \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "And its transpose looks like:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "b_{\\text{n1}} & b_{\\text{n2}} \\\\ \n",
    "w_{1\\text{n}_1} & w_{1\\text{n}_2} \\\\ \n",
    "w_{2\\text{n}_1} & w_{2\\text{n}_2} \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "Multiplied together you get: $ F \\cdot {\\Theta^{(1)}}^T$. 2 by 3 times 3 by 2 will make a 2 by 2 matrix of the weighted sums like so, $Z^{(l)} =$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "1 \\cdot \\text{bias}_{\\text{neuron}_1} + \\text{feat}_{1,\\text{val}_1} \\cdot \\text{weight}_{\\text{input}_1,\\text{neuron}_1} + \\text{feat}_{2,\\text{val}_1} \\cdot \\text{weight}_{\\text{input}_2,\\text{neuron}_1} & \n",
    "1 \\cdot \\text{bias}_{\\text{neuron}_2} + \\text{feat}_{1,\\text{val}_2} \\cdot \\text{weight}_{\\text{input}_1,\\text{neuron}_2} + \\text{feat}_{2,\\text{val}_2} \\cdot \\text{weight}_{\\text{input}_2,\\text{neuron}_2} \\\\  \n",
    "1 \\cdot \\text{bias}_{\\text{neuron}_1} + \\text{feat}_{1,\\text{val}_1} \\cdot \\text{weight}_{\\text{input}_1,\\text{neuron}_1} + \\text{feat}_{2,\\text{val}_1} \\cdot \\text{weight}_{\\text{input}_2,\\text{neuron}_1} &  \n",
    "1 \\cdot \\text{bias}_{\\text{neuron}_2} + \\text{feat}_{1,\\text{val}_2} \\cdot \\text{weight}_{\\text{input}_1,\\text{neuron}_2} + \\text{feat}_{2,\\text{val}_2} \\cdot \\text{weight}_{\\text{input}_2,\\text{neuron}_2}  \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Or, in a WAY more legible way:\n",
    "\n",
    "$$\n",
    "Z^{(l)} =\n",
    "\\begin{bmatrix} \n",
    "z^{(l)}_{1,1} & z^{(l)}_{1,2} \\\\  \n",
    "z^{(l)}_{2,1} & z^{(l)}_{2,2}  \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "In this matrix, each row contains the weighted sums, $z^{(l)}$ for this layer for a certain training example, with column 1 corresponding to neuron 1, and column 2 corresponding to neuron 2. We can now perform the sigmoid on this layer to get the activations. I'm shortening the terms to make things more legible.\n",
    "\n",
    "\n",
    "$$\n",
    "A^{(l)} =\n",
    "\\begin{bmatrix}\n",
    "\\sigma( b_1 + f_{1} v_{1} \\cdot w_1 n_1 + f_2 v_1 \\cdot w_2 n_1 ) &\n",
    "\\sigma( b_2 + f_1 v_2 \\cdot w_1 n_2 + f_2 v_2 \\cdot w_2 n_2 ) \\\\\n",
    "\\sigma( b_1 + f_1 v_1 \\cdot w_1 n_1 + f_2 v_1 \\cdot w_2 n_1 ) &\n",
    "\\sigma( b_2 + f_1 v_2 \\cdot w_1 n_2 + f_2 v_2 \\cdot w_2 n_2 )\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "a^{(l)}_1 & a^{(l)}_2 \\\\\n",
    "a^{(l)}_1 & a^{(l)}_2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "------------------\n",
    "Where you are now:\n",
    "* you take input features\n",
    "* you prepend a column of ones\n",
    "* you multiply this with a matrix that contains biases (to be multiplied with 1) and weights (to be multiplied with each feature value).\n",
    "* This gives you a first matrix of weighted sums for the first layer, in this case 2 by 2, for 2 samples and 2 neurons.\n",
    "* You put this through the sigmoid activation function so you can fit nonlinear processes.\n",
    "\n",
    "So far so good, this is the meaning of the matrix $A^{(l)}$. We now do basically the same trick once more, until we get to the output layer:\n",
    "\n",
    "* These so-called activations $A^{(l)}$ are now the **features** for the next layer, so below you will start the process again: i) prepend ones; ii) multiply with matrix; iii) obtain weighted sums; iv) get activations.\n",
    "* There it ends, since we have just two layers here. The final activations are the probabilities for the class.\n",
    "\n",
    "Ready? Here goes:\n",
    "__________________\n",
    "\n",
    "\n",
    "Now we take this $A^{(l)}$, add a column of 1 to be multiplied with the biases in ${\\Theta^{(2)}}^T$ and do that multiplication. Note that I've added the layer indices as superscript ${}^{\\mathbf{L}}$\n",
    " to distinguish them from the previous layer's biases and weights:\n",
    "\n",
    "$$\n",
    "Z^{(L)} = \\begin{bmatrix} 1 & a^{(l)}_1 & a^{(l)}_2 \\\\ 1 & a^{(l)}_1 & a^{(l)}_2 \\end{bmatrix} \\cdot \\begin{bmatrix} b^{L}_1 & b^{(L)}_2 & b^{(L)}_3 \\\\ w_1n_1^{(L)} & w_1n_2^{(L)} & w_1n_3^{(L)} \\\\ w_2n_1^{(L)} & w_2n_2^{(L)} & w_2n_3^{(L)}\\end{bmatrix} = \\begin{bmatrix} z^{(L)}_1 & z^{(L)}_2 & z^{(L)}_3 \\\\ z^{(L)}_1 & z^{(L)}_2 & z^{(L)}_3 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Where again the first row are the weighted sums. Using the sigmoid activation function we get: \n",
    "$$\n",
    "\\sigma(Z^{(L)}) = A^{(L)} = \\begin{bmatrix} a^{(L)}_1 & a^{(L)}_2 & a^{(L)}_3 \\\\ a^{(L)}_1 & a^{(L)}_2 & a^{(L)}_3 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "It's these final activations that you can compare with labels, which look like this:\n",
    "$$\n",
    "Y = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "## Backpropagation linear algebra\n",
    "\n",
    "So finally, because of the cross entropy cost function (which allows us to skip multiplying with $\\sigma'()$), we get: \n",
    "$$\n",
    "\\delta^{(L)} = A^{(L)} - Y\n",
    "$$ This brings us back to this image, where you'd begin backpropagation with the _average error_ of the neurons over each training example if you weren't using linear algebra. With linear algebra, it's easier to do the averaging later, so we'll work with the 2 by 3 matrix of $\\delta$ values for the 2 training samples:\n",
    "![image](ToyNetworkLinAlg3.PNG)\n",
    "\n",
    "Now let's get us some partial derivatives!\n",
    "1. **Partial derivatives w.r.t. weights and biases output layer**: for the biases, this is just $\\delta^{(L)}$. Thinking in linear algebra, we thus need to multiply them with a column or row of ones in some matrix. For the weights, it's each element of $\\delta^{(L)}$ multiplied with the activations of the previous layer that led to it $A^{(l)}$. Note that I've added indices like $s_1$ to indicate sample 1 or sample 2. So we get: $$ {\\delta^{(L)}}^T \\cdot \\begin{bmatrix} 1 & a^{(l)}_1s_1 & a^{(l)}_2s_1 \\\\ 1 & a^{(l)}_1s_2 & a^{(l)}_2s_2 \\end{bmatrix} = \\begin{bmatrix} 0.6 & 0.8 \\\\ 0.4 & -0.3 \\\\ 0.03 & 0.54 \\end{bmatrix} \\cdot \\begin{bmatrix} 1 & a^{(l)}_1s_1 & a^{(l)}_2s_1 \\\\ 1 & a^{(l)}_1s_2 & a^{(l)}_2s_2 \\end{bmatrix} = \\begin{bmatrix} 0.6 \\cdot 1 + 0.8 \\cdot 1 & 0.6 \\cdot a^{(l)}_1s_1  + 0.8 \\cdot a^{(l)}_1s_2  & 0.6 \\cdot a^{(l)}_2s_1 + 0.8 \\cdot a^{(l)}_2s_2  \\\\ 0.4 \\cdot 1 + -0.3 \\cdot 1 & 0.4 \\cdot a^{(l)}_1s_1 + -0.3 \\cdot a^{(l)}_1s_2 & 0.4 \\cdot a^{(l)}_2s_1 + -0.3 \\cdot a^{(l)}_2s_2 \\\\ 0.03 \\cdot 1 + 0.54 \\cdot 1 & 0.03 \\cdot a^{(l)}_1s_1 + 0.54 \\cdot a^{(l)}_1s_2 & 0.03 \\cdot a^{(l)}_2s_1 + 0.54 \\cdot a^{(l)}_2s_2 \\end{bmatrix}$$ What you see is that this is a matrix which has in its rows the sums of the gradient for each neuron. Thus, in the first row, the first column just has the summed $\\delta^{(L)}$-values for that neuron: exactly the partial derivative of the cost w.r.t. the bias of neuron 1 in the output layer, summed over the training examples! The second column has the partial derivative of the cost w.r.t. the first weight of neuron 1 in the output layer, summed over the training examples. Finally, the third column has the partial derivative of the cost w.r.t. the second weight of neuron 1 in the output layer, summed over the training examples. The second and third row have this for the other two neurons in the output layer. To go from this sum to the gradient, all we have to do is multiply with $\\frac{1}{m}$, which in this case is $\\frac{1}{2}$: $$\\Delta^{(L)} = \\frac{1}{m}\\begin{bmatrix} 0.6 \\cdot 1 + 0.8 \\cdot 1 & 0.6 \\cdot a^{(l)}_1s_1  + 0.8 \\cdot a^{(l)}_1s_2  & 0.6 \\cdot a^{(l)}_2s_1 + 0.8 \\cdot a^{(l)}_2s_2  \\\\ 0.4 \\cdot 1 + -0.3 \\cdot 1 & 0.4 \\cdot a^{(l)}_1s_1 + -0.3 \\cdot a^{(l)}_1s_2 & 0.4 \\cdot a^{(l)}_2s_1 + -0.3 \\cdot a^{(l)}_2s_2 \\\\ 0.03 \\cdot 1 + 0.54 \\cdot 1 & 0.03 \\cdot a^{(l)}_1s_1 + 0.54 \\cdot a^{(l)}_1s_2 & 0.03 \\cdot a^{(l)}_2s_1 + 0.54 \\cdot a^{(l)}_2s_2 \\end{bmatrix}$$ This'll average the gradients over all training examples, giving you the gradient w.r.t. the bias and cost for each neuron in the output layer! <br> . Note that this matrix is exactly in the shape of $\\Theta^{(2)}$, which looks like: $$\\begin{bmatrix} b^{(L)}_1 & w_1n_1^{(L)} & w_2n_1^{(L)} \\\\ b^{(L)}_2  & w_1n_2^{(L)} & w_2n_2^{(L)}  \\\\ b^{(L)}_3  & w_1n_3^{(L)} & w_2n_3^{(L)}\\end{bmatrix}$$ So if you'd want to take a gradient step, you could just do $$\\Theta^{(2)}_{new} = \\Theta^{(2)} - \\frac{\\alpha}{m} \\cdot \\begin{bmatrix} 0.6 \\cdot 1 + 0.8 \\cdot 1 & 0.6 \\cdot a^{(l)}_1s_1  + 0.8 \\cdot a^{(l)}_1s_2  & 0.6 \\cdot a^{(l)}_2s_1 + 0.8 \\cdot a^{(l)}_2s_2  \\\\ 0.4 \\cdot 1 + -0.3 \\cdot 1 & 0.4 \\cdot a^{(l)}_1s_1 + -0.3 \\cdot a^{(l)}_1s_2 & 0.4 \\cdot a^{(l)}_2s_1 + -0.3 \\cdot a^{(l)}_2s_2 \\\\ 0.03 \\cdot 1 + 0.54 \\cdot 1 & 0.03 \\cdot a^{(l)}_1s_1 + 0.54 \\cdot a^{(l)}_1s_2 & 0.03 \\cdot a^{(l)}_2s_1 + 0.54 \\cdot a^{(l)}_2s_2 \\end{bmatrix} $$ <br> <br>\n",
    "\n",
    "2. **Partial derivatives w.r.t. weighted sums in the previous layer ($Z^{(l)}$), i.e. propagating back the error**: Remember, the steps we need to take are: multiplying $\\delta^{(L)}$ with the weights (which are in $\\Theta^{(2)}$) and then multiplying with the derivative of the sigmoid on the weighted sums that the Hidden Layer produces ($\\sigma(Z^{(l)})$. To do that first multiply the two together: $$\\begin{bmatrix} 0.6 & 0.4 & 0.03 \\\\ 0.8  & -0.3 & 0.54 \\end{bmatrix} \\cdot \\begin{bmatrix} b^{(L)}_1 & w_1n_1^{(L)} & w_2n_1^{(L)} \\\\ b^{(L)}_2  & w_1n_2^{(L)} & w_2n_2^{(L)}  \\\\ b^{(L)}_3  & w_1n_3^{(L)} & w_2n_3^{(L)}\\end{bmatrix}$$ You'll see that there's something wrong here: there's biases, but the partial derivative only includes the weight, not them. So only include the 2nd to last column of $\\Theta^{(2)}$ instead: $$\\begin{bmatrix} 0.6 & 0.4 & 0.03 \\\\ 0.8  & -0.3 & 0.54 \\end{bmatrix} \\cdot \\begin{bmatrix}  w_1n_1^{(L)} & w_2n_1^{(L)} \\\\ w_1n_2^{(L)} & w_2n_2^{(L)}  \\\\ w_1n_3^{(L)} & w_2n_3^{(L)}\\end{bmatrix} = \\begin{bmatrix} 0.6 \\cdot w_1n_1^{(L)} + 0.4 \\cdot w_1n_2^{(L)} + 0.03 \\cdot w_1n_3^{(L)} & 0.6 \\cdot w_2n_1^{(L)} + 0.4 \\cdot w_2n_2^{(L)} + 0.03 \\cdot w_2n_3^{(L)} \\\\ 0.8 \\cdot w_1n_1^{(L)} + -0.3 \\cdot w_1n_2^{(L)} + 0.54 \\cdot w_1n_3^{(L)} & 0.8 \\cdot w_2n_1^{(L)} + -0.3 \\cdot w_2n_2^{(L)} + 0.54 \\cdot w_2n_3^{(L)} \\end{bmatrix}$$ This gives us a matrix very similar to $\\delta^{(L)}$. Only now there's just 2 columns for the 2 neurons in the HL! The final thing that's left to do is to multiply each of these values with the corresponding sigmoid derivative: $$\\sigma'(Z^{(l)}) = \\sigma'(\\begin{bmatrix}  1 \\cdot b_1 + f_{1}v_{1} \\cdot w_1n_1 + f_2v_1 \\cdot w_2n_1 & 1 \\cdot b_1 + f_1v_2 \\cdot w_1n_1 + f_2v_2 \\cdot w_2n_1 \\\\  1 \\cdot b_2 + f_1v_1 \\cdot w_1n_2 + f_2v_1 \\cdot w_2n_2 &  1 \\cdot b_2 + f_1v_2 \\cdot w_1n_2 + f_2v_2 \\cdot w_2n_2 \\end{bmatrix})$$ Note that you already calculate $Z^{(l)}$ in the forward pass. In total, it looks like: $$\\begin{bmatrix} 0.6 & 0.4 & 0.03 \\\\ 0.8  & -0.3 & 0.54 \\end{bmatrix} \\cdot \\begin{bmatrix}  w_1n_1^{(L)} & w_2n_1^{(L)} \\\\ w_1n_2^{(L)} & w_2n_2^{(L)}  \\\\ w_1n_3^{(L)} & w_2n_3^{(L)}\\end{bmatrix} \\odot \\begin{bmatrix}  \\sigma'(1 \\cdot b_1 + f_{1}v_{1} \\cdot w_1n_1 + f_2v_1 \\cdot w_2n_1) & \\sigma'(1 \\cdot b_1 + f_1v_2 \\cdot w_1n_1 + f_2v_2 \\cdot w_2n_1) \\\\  \\sigma'(1 \\cdot b_2 + f_1v_1 \\cdot w_1n_2 + f_2v_1 \\cdot w_2n_2) &  \\sigma'(1 \\cdot b_2 + f_1v_2 \\cdot w_1n_2 + f_2v_2 \\cdot w_2n_2) \\end{bmatrix}$$ This'll give you $\\delta^{(l)}$, which looks like: <br> $$\\begin{bmatrix} \\delta_1^{(l)} & \\delta_2^{(l)} \\\\ \\delta_1^{(l)} & \\delta_2^{(l)} \\end{bmatrix}$$\n",
    "\n",
    "3. **Partial derivatives w.r.t. weights and biases Hidden Layer**: now you can do the exact same thing as under point 1. above. The only difference is that the 'activations' of the previous layer are now just the input values. Once this step is done, you have all the gradients!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ab9f9c",
   "metadata": {},
   "source": [
    "## Finally: the actual implementation, the real deal, the pièce de resistance:\n",
    "\n",
    "It's now up to you to implement backpropagation as described. This is slightly daunting. Take the following steps:\n",
    "* Make a copy of `nnCostFunction`. Call it `nnGradientFunction`. It keeps the same arguments and does exactly the same to begin with, but it will return the gradients calculated by backpropagation rather than stop at calculating the cost function. First set it to return `None`. \n",
    "* Calculate $\\delta^{(L)}$ using the real labels. Remember, this is just $A^{(L)} - y$.\n",
    "* Calculate the gradient matrix $\\Delta^{(L)}$ by following step 1. above. Don't forget to multiply with 1 over m!\n",
    "* Propagate the error back to calculate $\\delta^{(l)}$. Follow step 2. above. Use `mySigmoidGradient()` and know that $\\odot$ simply corresponds to * in numpy.\n",
    "* Calculate $\\Delta^{(l)}$ by doing the same thing as for $\\Delta^{(L)}$, but using the input values `np.c_[np.ones(shape = (len(X), 1)), X]` as the 'activations' of the previous layer.\n",
    "* Make the function return a flat array of the gradients so we can use it with advanced optimisers like `fmin_bfg()`. To do that, use `np.ravel()` on both matrices of gradients, and then append them to each other using `np.append(ravelledThetaOneGradientMatrix, ravelledThetaTwoGradientMatrix)`. This array should have an equal amount of entries as the nnThetas that the function takes in!\n",
    "\n",
    "Hints:\n",
    "* If you get stuck, be sure to print the .shape attribute of the matrices you are working with.\n",
    "* Don't forget to add a column of ones to the activations of the previous layer to be multiplied with the $\\delta^{(L)}$ or $\\delta^{(l)}$ matrix: this results in the gradient of the bias term, which is just $\\delta^{(L)}_j$\n",
    "* If things seem hopeless, ask a fellow sufferer (student) for help, clamour for attention from one of the teachers (bonus points if you just yell 'ATTENTION!'), or, if all else fails and the nuclear option is required, ~~Give Putin a call~~ look at the answers. If you've been trying for 20 minutes and are just stuck, that's exactly the type of situation the answers are there for!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8fbbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import default_rng\n",
    "\n",
    "rng = default_rng(42)\n",
    "thetaOneMatrix = rng.uniform(-0.12, 0.12, size=(25, 785))\n",
    "thetaTwoMatrix = rng.uniform(-0.12, 0.12, size=(10, 26))\n",
    "\n",
    "savedData = np.load(\"dataMNISTNeuralNetwork.npz\")\n",
    "X_train, X_test, y_train, y_test = (\n",
    "    savedData[\"XTrain\"],\n",
    "    savedData[\"XTest\"],\n",
    "    savedData[\"yTrain\"],\n",
    "    savedData[\"yTest\"],\n",
    ")\n",
    "\n",
    "\n",
    "nnThetas = np.append(np.ravel(thetaOneMatrix), np.ravel(thetaTwoMatrix))\n",
    "inputLayerSize = 784\n",
    "hiddenLayerSize = 25\n",
    "classLabels = 10\n",
    "X = X_train\n",
    "y = y_train\n",
    "\n",
    "# Up to you! Copy the function from above and go ahead.\n",
    "\n",
    "\n",
    "# testing afterwards\n",
    "test = nnGradientFunction(nnThetas, X, y)\n",
    "print(np.array(test).shape)\n",
    "print(nnThetas.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a856ef",
   "metadata": {},
   "source": [
    "## Testing your calculations with numerical gradient computations\n",
    "\n",
    "Implementing backpropagation probably took entirely too long. That's not strange: pouring this idea correctly into the linear algebra mould when you've only just learned about it is gratuitously difficult. Hopefully you managed to make it through, with or without the answers. Now we're going to check that the gradients we've calculated are correct. For that, let's use the numerical gradient computation function defined earlier. The implementation we use below stops after the first _indexToStop_ (here 200) theta parameters (out of a whopping 19,885) because otherwise it would take _hours_. \n",
    "\n",
    "This is of course just an approximation, so the gradients will only be correct up to the first ~3 digits after the comma. Let's check that the rounded entries of the numerical approximation agree with those of the actual gradient computation via backpropagation. You can just run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4aa55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = nnGradientFunction(nnThetas, X, y)\n",
    "\n",
    "# Don't run this cell multiple times!\n",
    "numericApproxGrad = numericalGradientApproximation(nnThetas, X, y, indexToStop=200)\n",
    "roundedNumApproxGrad = np.round(numericApproxGrad, 3)\n",
    "\n",
    "# are these rounded entries all the same?\n",
    "print(\n",
    "    np.all(np.isclose(test[0 : len(numericApproxGrad)], numericApproxGrad, atol=0.01))\n",
    ")\n",
    "# they should be!\n",
    "\n",
    "# print the matched entries (gradient descent value ; numerical value)\n",
    "k = zip(test, numericApproxGrad)\n",
    "for analytical, numerical in k:\n",
    "    print(str(analytical) + \" ; \" + str(numerical))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b651ebbc",
   "metadata": {},
   "source": [
    "## Moving on: adding regularisation and training the network\n",
    "\n",
    "If the above did not return the same values for you and you've been repeatedly smashing your face into your desk, laptop, or other assorted objects in the vicinity out of frustration, feel free to copy the correct implementation of `nnGradientFunction` from the answers. It's now time to add one last change: we need to add regularisation to the gradients (partial derivatives) of our theta's. \n",
    "\n",
    "Luckily, it turns out that, like before, you can do this after you've already computed the gradients: <br>\n",
    "![RegularisationCostAddedToGradients](RegularisationCostAddedToGradients.PNG) <br> <br>\n",
    "\n",
    "This shows it in a loop. But we have the gradients of our two theta matrices. And so, you can simply add $$\\frac{\\lambda}{m} \\cdot \\Theta^{(1)}$$ to $\\Theta^{(1)}$ (excluding the biases in the first column!), and likewise, $$\\frac{\\lambda}{m} \\cdot \\Theta^{(2)}$$ to $\\Theta^{(2)}$ (again, do nothing to the bias terms!). <br> <br>\n",
    "\n",
    "Up to you to:\n",
    "* Copy the nnGradientFunction from above and add the regularisation terms to the gradient!\n",
    "\n",
    "Hint:\n",
    "* The easiest implementation is to just set the first column of `thetaOneMatrix` and `thetaTwoMatrix` to 0, and to then add them $\\cdot \\frac{\\lambda}{m}$ to the matrices of gradients you calculated before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45218cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer\n",
    "\n",
    "\n",
    "# testing\n",
    "testRegularised = nnGradientFunction(nnThetas, X, y, lambda_=50)\n",
    "print(testRegularised.shape)\n",
    "print(nnThetas.shape)\n",
    "print(test[0:30])\n",
    "print(testRegularised[0:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9b454d",
   "metadata": {},
   "source": [
    "## Training the neural network with your brand-spankin' new function\n",
    "\n",
    "Finally, the time has come to face your destiny: training a neural network to classify some digits in an afternoon practical. It's a simple destiny, as destinies go, but a worthwhile one nonetheless. Besides, the other choice is facing the fact that destinies don't exist and existence is meaningless, so have at it!\n",
    "\n",
    "* Use your favourite pal `fmin_cg` to minimise this function. See the documentation [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fmin_cg.html). Assign the result to `trainedNeuralNetwork`. Use a $\\lambda$ of 1, and be sure to set `maxiter = 60`.\n",
    "\n",
    "Hint:\n",
    "* This will take ~10 minutes to run. Feel free to grab something to drink (I recommend the blood of your enemies) or take a short walk. \n",
    "\n",
    "**Note**:\n",
    "* See how I start the two theta matrices with random uniform numbers? There's actually a very good reason for that. Remember, with logistic and linear regression, I regularly just set the start parameters to an array of zeros. That wouldn't work here. Why? Because then the partial derivative w.r.t. every weight and bias would be exactly the same, and nothing could be learned! Hence, it is necessary to break this symmetry by randomly initialising. See [part 1 here](https://www.deeplearning.ai/ai-notes/initialization/) to test it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c6b3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = default_rng(42)\n",
    "thetaOneMatrix = rng.uniform(-0.12, 0.12, size=(25, 785))\n",
    "thetaTwoMatrix = rng.uniform(-0.12, 0.12, size=(10, 26))\n",
    "initialThetas = np.append(np.ravel(thetaOneMatrix), np.ravel(thetaTwoMatrix))\n",
    "\n",
    "\n",
    "def mySigmoid(data):\n",
    "    data = np.array(data)\n",
    "    return scipy.special.expit(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9270c246",
   "metadata": {},
   "source": [
    "## Seeing your performance on the train and test set.\n",
    "\n",
    "Wow, you've made it. Let's see how well you do on the train and test sets.\n",
    "\n",
    "To do that: \n",
    "\n",
    "* Use the reconstituted $\\Theta^{(1)}$ and $\\Theta^{(2)}$ matrices, along with the `forwardPass()` function below to perform forward passes for the train and test set.\n",
    "* Use `np.where` and `np.amax` (with `axis = 1`) to turn the raw numbers into class label vectors with 0 and 1. Or use `np.argmax` to do it in one step.\n",
    "* Use `np.all` to check whether the labels are the same as the true labels or not, and calculate a % of correctly classified images.\n",
    "* Print these percentages.\n",
    "* **Optional** If you like, this same neural network trained for 500 iterations with a $\\lambda$ of 0, 1, 10, or 100 is available as the file \"500IterationsTrainedThetasLambdas0_1_10_100.npz\", which you can load in with `np.load()`. This yields a dictionary with as keys the names of the array. You can see how things differ if we train for longer and try multiple values for $\\lambda$. Access it by using `loadedData[\"thetaListLambdaZero\"|\"thetaListLambdaOne\"|\"thetaListLambdaTen\"|\"thetaListLambdaHundred\"]`.\n",
    "\n",
    "Hint:\n",
    "* If you don't quite know how to do this: I did it for you in the afternoon practical yesterday when drawing the misclassified digits. Look there.\n",
    "* DuckDuckGo (or Google) is your friend: look at the documentation of these Numpy functions.\n",
    "* First experiment with one row to see how to use each function to do what you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027312b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hiddenLayerSize = 25\n",
    "inputLayerSize = 784\n",
    "classLabels = 10\n",
    "hiddenLayerParamNr = hiddenLayerSize * (inputLayerSize + 1)\n",
    "thetaOneMatrixTrained = np.reshape(\n",
    "    trainedNeuralNetwork[0][0:hiddenLayerParamNr],\n",
    "    newshape=(hiddenLayerSize, inputLayerSize + 1),\n",
    ")\n",
    "outputLayerParamStart = hiddenLayerParamNr\n",
    "thetaTwoMatrixTrained = np.reshape(\n",
    "    trainedNeuralNetwork[0][outputLayerParamStart:],\n",
    "    newshape=(classLabels, hiddenLayerSize + 1),\n",
    ")\n",
    "\n",
    "\n",
    "def forwardPass(X, y, thetaOne=thetaOneMatrixTrained, thetaTwo=thetaTwoMatrixTrained):\n",
    "    xInputs = np.c_[np.ones(shape=(len(X), 1)), X]\n",
    "    firstLayerWeightedSum = xInputs @ thetaOne.T\n",
    "    firstLayerActivations = mySigmoid(firstLayerWeightedSum)\n",
    "    secondLayerInputs = np.c_[\n",
    "        np.ones(shape=(len(firstLayerActivations), 1)), firstLayerActivations\n",
    "    ]\n",
    "    secondLayerWeightedSum = secondLayerInputs @ thetaTwo.T\n",
    "    secondLayerActivations = mySigmoid(secondLayerWeightedSum)\n",
    "    return secondLayerActivations\n",
    "\n",
    "\n",
    "# your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137807a7",
   "metadata": {},
   "source": [
    "## The cool thing about working with images: visualising what your NN has learned!\n",
    "\n",
    "As I've told you in the lectures, each hidden unit learns some feature representation that allows the next layer of logistic regressors to better differentiate the (here 10) different classes. So neural networks will learn their own transformations of input features to get best classification performance: no manual feature encodings by humans needed.\n",
    "\n",
    "Now, these Hidden Layer units have 784 weights, 1 for each pixel. So, what if we create a 28\\*28 image of those weights? This will show us how strongly each weight reacts to each pixel input. In other words: it will show us what the HL units have learned to recognise/what strongly triggers their activation. The below shows you how that looks!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b57b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weightsOnly = thetaOneMatrixTrained[:, 1:]\n",
    "\n",
    "\n",
    "figWeights, axWeights = plt.subplots(5, 5, figsize=(8, 8))\n",
    "counter = 0\n",
    "for row in range(0, len(axWeights)):\n",
    "    for col in range(0, len(axWeights)):\n",
    "        axWeights[row, col].imshow(\n",
    "            weightsOnly[counter, :].reshape(28, 28), cmap=\"gray\", interpolation=\"none\"\n",
    "        )\n",
    "        axWeights[row, col].set_title(\"Weight \" + str(counter + 1))\n",
    "        axWeights[row, col].set_axis_off()\n",
    "        counter += 1\n",
    "figWeights.suptitle(\"Plot of weights\")\n",
    "figWeights.tight_layout()\n",
    "\n",
    "\n",
    "# plot a few digits for comparison:\n",
    "\n",
    "figDigits, axDigits = plt.subplots(3, 3, figsize=(5, 5))\n",
    "counter = 0\n",
    "for row in range(0, len(axDigits)):\n",
    "    for col in range(0, len(axDigits)):\n",
    "        digit = np.reshape(\n",
    "            X_train[counter + np.ceil(np.random.rand() * 10000).astype(int), :],\n",
    "            newshape=(28, 28),\n",
    "        )\n",
    "        axDigits[row, col].imshow(digit, cmap=\"gray\", interpolation=\"none\")\n",
    "        axDigits[row, col].set_axis_off()\n",
    "        counter += 1\n",
    "figDigits.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed15c605",
   "metadata": {},
   "source": [
    "## Understanding the weights\n",
    "\n",
    "It's not too clear what _exactly_ the weights are capturing, but some weights really seem to be capturing specific strokes, just like in the 3Blue1Brown video. For example, weight 5 seems to capture the upward stroke of a 1 or 7, and weight 20 seems to be capturing something vaguely 8-like.\n",
    "\n",
    "However, it should be noted that this network uses nothing of the spatial information that we use: every neuron in the HL is connected to every input pixel. So, if you were to scramble each image in the same way, it would classify exactly as well even though for us the digit identity is completely lost. The idea that image elements might occur in more than one location and that local features (pixels) are highly correlated is an _inductive bias_ that is used in convolutional neural networks. Backpropagation was more than enough hassle so looking at convolutions is optional, as long as you know what the idea is you're good. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483379d8",
   "metadata": {},
   "source": [
    "## What I want you to remember here:\n",
    "* How backpropagation works\n",
    "* A bit of detail of how the maths works: if I ask you to write down the series of partial derivatives you need to get the partial derivative w.r.t. the weights and biases of a certain neuron in a diagram, I expect you to be able to give it. Perhaps not with perfect math notation, but very close.\n",
    "* How convolutions work and can help make powerful deep learning classifiers (specifically on images)\n",
    "\n",
    "## The end \n",
    "\n",
    "Wow, backpropagation is a real baguette in the donkey. Still, you're here. Well done! \n",
    "\n",
    "## Survey\n",
    "This wouldn't be a true Jupyter notebook for this course without a link. [Go ahead and fill this bad boy out!](https://docs.google.com/forms/d/e/1FAIpQLSeCfdD2N_6RswisczSV3y8kuun9dBCZGaR26JpYjZibGU-HrA/viewform?usp=sf_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bc0ba9",
   "metadata": {},
   "source": [
    "# OPTIONAL\n",
    "\n",
    "Here's a bit of fiddling with convolution yourself. It's optional: you've had enough to do! Just understand that convolutional neural networks include inductive biases that greatly aid performance on images while cutting down on parameters. Win-win!\n",
    "\n",
    "## Convolving filters yourself\n",
    "\n",
    "The image below is the most exciting image ever to be classified in the history of neural networks. Gaze upon it and weep: <br>\n",
    "![Square](Square.PNG) <br>\n",
    "To aid in the monumental task of seeing where the square's edges are, you're going to use convolution. You'll use these two 3\\*3 filters for that: <br>\n",
    "![Filter1](EdgeFilter1.PNG) ![Filter2](EdgeFilter2.PNG)\n",
    "\n",
    "Here, the values in the cells are the weights for that cell. Remember, to perform a convolution you position the filter over a certain focal pixel, multiply the weights in the filter with the correct underlying pixel values, sum it, add a bias (if using), put that into the activation function (if using) and that's the first entry of your output. Then you slide the filter 1 (or more pixels, if you want) to the right and do it again. If you reach the edge, you move one pixel down and go all the way back to the left, sliding it to the right once more: ![convolution](keras_conv2d_padding.GIF). \n",
    "\n",
    "You'll run into trouble at the edges of the image: there the kernel will overlap with non-existent pixels. For this, you use padding, which you already saw in the image above.\n",
    "\n",
    "Up to you to: \n",
    "* Add zero-padding to the square image. You just need 1 row of zeros along the bottom and top, and one column of zeros at the beginning and end of the array. You can do this easily with [np.pad()](https://numpy.org/doc/stable/reference/generated/numpy.pad.html)\n",
    "* Loop over the columns and rows (in that order) of the image, excepting the first and last column and row. Multiply the values in the first filter with the corresponding pixel intensities in the image, then sum them. Save these values in a new array.\n",
    "* Do the same for the second filter\n",
    "* Use `plt.imshow()` with `plt.show()` to visualise your edge detector outputs!\n",
    "* See if there's any edge detected that you wouldn't want to take into account, and also try to understand why it looks the way it looks!\n",
    "\n",
    "Hints:\n",
    "* Remember that Python's from-to function `range` excludes the final value: if you want to go from currentPixel-1 to currentPixel+1 (so 3 pixels), you need (currentPixel-1):(currentPixel+2)\n",
    "* You should not start at index 0 in your padded image (after all, then the padding has no use!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800d1818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "\n",
    "squareImage = np.array(ImageOps.grayscale(Image.open(\"Square.PNG\"))) * 1 / 255\n",
    "filterOne = np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]])\n",
    "filterTwo = np.array([[-1, -1, -1], [0, 0, 0], [1, 1, 1]])\n",
    "\n",
    "print(squareImage.shape)\n",
    "plt.imshow(squareImage, cmap=\"gray\", vmin=0, vmax=1)\n",
    "plt.show()\n",
    "\n",
    "# your answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5da238b",
   "metadata": {},
   "source": [
    "## Keras convolutional neural network on MNIST data\n",
    "\n",
    "An accuracy of 93% on the test set using a dense neural network is nothing to scoff at, but you know that convolutional neural networks (along with other innovations like Dropout and other activation functions) are what made the real leaps in performance possible. Using the Keras library, you can easily train your own convolutional neural network. \n",
    "\n",
    "I will discuss Keras in a bit more detail next Monday. For now, you can do the following:\n",
    "\n",
    "* Go [here](https://keras.io/examples/vision/mnist_convnet/) and input the commands there into the code cell(s) below. You could copy all the code, but typing some of it yourself might give you more of an idea of what you're doing so it's probably preferable.\n",
    "* As you step through it be sure to search for things you don't know about and think about the dimensionality. What is the total dimensionality of the data after you've run 32 convolutional filters over it? `model.summary()` shows this, but see if you get it.\n",
    "* As an **optional** question: you could try to get the untrained and trained filter weights and visualise them to see what sort of features in the image each filter has become attuned to. See [this question on Stackoverflow](https://stackoverflow.com/questions/43305891/how-to-correctly-get-layer-weights-from-conv2d-in-keras?noredirect=1&lq=1) and [this link about getting weights from a Keras model](https://www.codespeedy.com/get_weights-and-set_weights-functions-in-keras-layers/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbbb10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "vscode": {
   "interpreter": {
    "hash": "56939404f97597fcbed2017c32e26dd1bd8b3368e8d6f036e6b1df162682998c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
