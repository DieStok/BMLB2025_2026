{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8110712",
   "metadata": {},
   "source": [
    "## Cleaning up the dataset\n",
    "\n",
    "The dirty secret of ML is that you spend most of your time cleaning data. So you'll have to spend some time on that here. Do the following:\n",
    "\n",
    "* Replace the 0 values with `np.nan` (**Note**: be aware that you shouldn't do this for all columns. Think about it.)\n",
    "* Use [sklearn.impute.KNNImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html) to impute values that are missing for those columns where you inserted NaNs. Those who have followed the BiBC Essentials Course might remember K-Nearest Neighbour clustering. This function determines the (by default) 5 most similar samples (based on data that is _not_ missing) and sets the bmi/glucose level, etc. to the mean of their values. Euclidean distance is used. We will discuss K-Nearest Neighbour clustering in two days. For now, you can just use it. To do so, use `a = KNNImputer(missing_values = np.nan)` followed by `imputedData = a.fit_transform(nonImputedData)`.\n",
    "* Note that this turns the DataFrame into a numpy array: this is not a problem but it's good to know.\n",
    "* Mean-normalise (i.e. subtract the mean and divide by the standard deviation) the features using the function provided below. This should be done on all the data except the labels.\n",
    "* Put the class into a `np.array` (a column vector) called `diabetesClassLabels`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c518f41",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b5ed4c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "\n",
    "def createNormalisedFeatures(featureArray, mode=\"range\", printit=False):\n",
    "    if printit:\n",
    "        print(featureArray)\n",
    "    featureMeans = np.mean(featureArray, axis=0, keepdims=True)\n",
    "    if printit:\n",
    "        print(featureMeans)\n",
    "    if printit:\n",
    "        print(featureArray - featureMeans)\n",
    "    if mode == \"range\":\n",
    "        featureRanges = np.max(featureArray, axis=0, keepdims=True) - np.min(\n",
    "            featureArray, axis=0, keepdims=True\n",
    "        )\n",
    "        # broadcasting in action:\n",
    "        normalisedFeatures = (featureArray - featureMeans) / featureRanges\n",
    "        return [normalisedFeatures, featureMeans, featureRanges]\n",
    "    elif mode == \"SD\":\n",
    "        featureSDs = np.std(featureArray, axis=0, keepdims=True)\n",
    "        # broadcasting in action:\n",
    "        normalisedFeatures = (featureArray - featureMeans) / featureSDs\n",
    "        return [normalisedFeatures, featureMeans, featureSDs]\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
